{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/cancer-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove the ID and the Unnamed column at the end\n",
    "#df = df.iloc[:,1:df.shape[1]-1]\n",
    "df.drop(['id','Unnamed: 32'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis                  0\n",
       "radius_mean                0\n",
       "texture_mean               0\n",
       "perimeter_mean             0\n",
       "area_mean                  0\n",
       "smoothness_mean            0\n",
       "compactness_mean           0\n",
       "concavity_mean             0\n",
       "concave points_mean        0\n",
       "symmetry_mean              0\n",
       "fractal_dimension_mean     0\n",
       "radius_se                  0\n",
       "texture_se                 0\n",
       "perimeter_se               0\n",
       "area_se                    0\n",
       "smoothness_se              0\n",
       "compactness_se             0\n",
       "concavity_se               0\n",
       "concave points_se          0\n",
       "symmetry_se                0\n",
       "fractal_dimension_se       0\n",
       "radius_worst               0\n",
       "texture_worst              0\n",
       "perimeter_worst            0\n",
       "area_worst                 0\n",
       "smoothness_worst           0\n",
       "compactness_worst          0\n",
       "concavity_worst            0\n",
       "concave points_worst       0\n",
       "symmetry_worst             0\n",
       "fractal_dimension_worst    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis\n",
       "B    357\n",
       "M    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the diagnosis column to 0,1 where 1 means that the cancer is malignant and 0 means it is benign\n",
    "# We can also perform label encoding. pd.getdummies. Maps are more efficient and easy.\n",
    "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape and count again to ensure that no record is dropped. \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis\n",
       "0    357\n",
       "1    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape and count again to ensure that no record is dropped. \n",
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis\n",
       "0    0.627417\n",
       "1    0.372583\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ratio/percentage of of the type of diagonistic data in the whole sample space. \n",
    "df['diagnosis'].value_counts()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare X and y by doing the following. \n",
    "\n",
    "# X is the entire data frame except diagnostic column. This are also the independent variables.\n",
    "X = df.drop(['diagnosis'],axis=1)\n",
    "\n",
    "# y is the diagnostic column, which is also the dependent variable. \n",
    "y = df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing, to perform stratified sammpling\n",
    "# Stratified sampling: dividing the whole data set into homogeneous groups called strata (stratum).\n",
    "\n",
    "# train_size is 80% // 80% of the data is used to train the model. Large data is required for the training.\n",
    "# random_state is 12345 // \n",
    "# stratify = y // to get a balanced data for the training. Can only be done on the dependent data (not on independent data).\n",
    "# the stratify sampling will ensure that the percentage of the split data is also same as the original data. \n",
    "# Random sampling may create certain imbalances in the training and test data and may lead to inaccuracies. \n",
    "X_train, X_test, y_train,y_test = train_test_split(X,\n",
    "                                                   y, \n",
    "                                                   stratify = y, \n",
    "                                                   train_size = 0.8, \n",
    "                                                   random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (455, 30) (455,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train shape {X_train.shape} {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape (114, 30) (114,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test shape {X_test.shape} {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale of certain data columns are different than each other. To unify the scale, standard scaling is performed.\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (x-mu)/sigma\n",
    "# Calculate Z values for each column divided by standard deviation. \n",
    "\n",
    "# Training dataset is used for training the model. So 'mu' and 'sigma' is inferred from the training set only.\n",
    "# Test dataset is used for validating the model. We keep the test set prstine. Don't learn or infer anything.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train) # Learn mean and standard deviaion on the train dataset. \n",
    "X_test_sc = scaler.transform(X_test) # Apply the same mean and std.dev to test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We transpose the X matrix so that rows become column and columns become rows. \n",
    "# Each column represents a sample and rows are the features\n",
    "# This is more memory efficient and metrix efficient. \n",
    "\n",
    "X_train_n = X_train_sc.T\n",
    "X_test_n = X_test_sc.T\n",
    "y_train_n = y_train.values.reshape(1,-1)\n",
    "y_test_n = y_test.values.reshape(1,-1)\n",
    "\n",
    "# Reshape is required otherwise metrix multiplication operation becomes difficult.\n",
    "# matrix multiplication, shape of the matrix needs to be correct. \n",
    "\n",
    "# Watch at 2:10:00 for the explanation of matrix using the derivative equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape (30, 455) (1, 455)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train shape {X_train_n.shape} {y_train_n.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape (30, 114) (1, 114)\n"
     ]
    }
   ],
   "source": [
    "print(f\"test shape {X_test_n.shape} {y_test_n.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define sigmoid function\n",
    "sc.special.expit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sigmoid = 1/(1+exp(-z))\n",
    "1/(1+np.exp(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights to 0. The number of weights are equal to the number of features.\n",
    "w = np.zeros((X_train_n.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column dimention of first metrcies should be equal to the row dimention of second metrics\n",
    "# If they are not same, it leads to multiple errros. \n",
    "\n",
    "## A -> (m,n), B -> (n,p)\n",
    "## A*B -> (m,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 0 # Initialize bias weight to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01 ## Learning Rate\n",
    "num_iters = 200 # Also known as Epochs (one forward and backward propogation is one epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the costs \n",
    "# Initialize the m. 'm' is summation of loss across all data sets. \n",
    "costs = []\n",
    "m = X_train_n.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "Iteration 70\n",
      "Iteration 71\n",
      "Iteration 72\n",
      "Iteration 73\n",
      "Iteration 74\n",
      "Iteration 75\n",
      "Iteration 76\n",
      "Iteration 77\n",
      "Iteration 78\n",
      "Iteration 79\n",
      "Iteration 80\n",
      "Iteration 81\n",
      "Iteration 82\n",
      "Iteration 83\n",
      "Iteration 84\n",
      "Iteration 85\n",
      "Iteration 86\n",
      "Iteration 87\n",
      "Iteration 88\n",
      "Iteration 89\n",
      "Iteration 90\n",
      "Iteration 91\n",
      "Iteration 92\n",
      "Iteration 93\n",
      "Iteration 94\n",
      "Iteration 95\n",
      "Iteration 96\n",
      "Iteration 97\n",
      "Iteration 98\n",
      "Iteration 99\n",
      "Iteration 100\n",
      "Iteration 101\n",
      "Iteration 102\n",
      "Iteration 103\n",
      "Iteration 104\n",
      "Iteration 105\n",
      "Iteration 106\n",
      "Iteration 107\n",
      "Iteration 108\n",
      "Iteration 109\n",
      "Iteration 110\n",
      "Iteration 111\n",
      "Iteration 112\n",
      "Iteration 113\n",
      "Iteration 114\n",
      "Iteration 115\n",
      "Iteration 116\n",
      "Iteration 117\n",
      "Iteration 118\n",
      "Iteration 119\n",
      "Iteration 120\n",
      "Iteration 121\n",
      "Iteration 122\n",
      "Iteration 123\n",
      "Iteration 124\n",
      "Iteration 125\n",
      "Iteration 126\n",
      "Iteration 127\n",
      "Iteration 128\n",
      "Iteration 129\n",
      "Iteration 130\n",
      "Iteration 131\n",
      "Iteration 132\n",
      "Iteration 133\n",
      "Iteration 134\n",
      "Iteration 135\n",
      "Iteration 136\n",
      "Iteration 137\n",
      "Iteration 138\n",
      "Iteration 139\n",
      "Iteration 140\n",
      "Iteration 141\n",
      "Iteration 142\n",
      "Iteration 143\n",
      "Iteration 144\n",
      "Iteration 145\n",
      "Iteration 146\n",
      "Iteration 147\n",
      "Iteration 148\n",
      "Iteration 149\n",
      "Iteration 150\n",
      "Iteration 151\n",
      "Iteration 152\n",
      "Iteration 153\n",
      "Iteration 154\n",
      "Iteration 155\n",
      "Iteration 156\n",
      "Iteration 157\n",
      "Iteration 158\n",
      "Iteration 159\n",
      "Iteration 160\n",
      "Iteration 161\n",
      "Iteration 162\n",
      "Iteration 163\n",
      "Iteration 164\n",
      "Iteration 165\n",
      "Iteration 166\n",
      "Iteration 167\n",
      "Iteration 168\n",
      "Iteration 169\n",
      "Iteration 170\n",
      "Iteration 171\n",
      "Iteration 172\n",
      "Iteration 173\n",
      "Iteration 174\n",
      "Iteration 175\n",
      "Iteration 176\n",
      "Iteration 177\n",
      "Iteration 178\n",
      "Iteration 179\n",
      "Iteration 180\n",
      "Iteration 181\n",
      "Iteration 182\n",
      "Iteration 183\n",
      "Iteration 184\n",
      "Iteration 185\n",
      "Iteration 186\n",
      "Iteration 187\n",
      "Iteration 188\n",
      "Iteration 189\n",
      "Iteration 190\n",
      "Iteration 191\n",
      "Iteration 192\n",
      "Iteration 193\n",
      "Iteration 194\n",
      "Iteration 195\n",
      "Iteration 196\n",
      "Iteration 197\n",
      "Iteration 198\n",
      "Iteration 199\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_iters):\n",
    "    print(f\"Iteration {i}\")\n",
    "    \n",
    "    ## Calculate prediction based on the weights. This is forward propagation. \n",
    "    ## Sigmoid(w.T*X+b)\n",
    "    A = sc.special.expit(np.dot(w.T,X_train_n)+b) ## Forward Propagation\n",
    "    \n",
    "    # Compute cost\n",
    "    cost = np.sum(((- np.log(A))*y_train_n + (-np.log(1-A))*(1-y_train_n)))/m\n",
    "    \n",
    "    ## Backward Propagation\n",
    "    dw = (np.dot(X_train_n,(A-y_train_n).T))/m ## dJ/dw\n",
    "    db = (np.sum(A-y_train_n))/m ## dJ/db\n",
    "    \n",
    "    ## Gradient Descent\n",
    "    w = w - alpha*dw # w = w - learning rate*dJ/dw\n",
    "    b = b - alpha*db # b = b - learning rate * dJ/db\n",
    "    \n",
    "    # Append cost for plotting\n",
    "    costs.append(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21359584],\n",
       "       [ 0.14465353],\n",
       "       [ 0.21440394],\n",
       "       [ 0.20878335],\n",
       "       [ 0.08440508],\n",
       "       [ 0.11786193],\n",
       "       [ 0.16658458],\n",
       "       [ 0.21363462],\n",
       "       [ 0.07761804],\n",
       "       [-0.05890534],\n",
       "       [ 0.16620667],\n",
       "       [-0.00330666],\n",
       "       [ 0.15561763],\n",
       "       [ 0.16643805],\n",
       "       [-0.03567052],\n",
       "       [ 0.00442397],\n",
       "       [-0.01177832],\n",
       "       [ 0.06132576],\n",
       "       [-0.02931021],\n",
       "       [-0.05960157],\n",
       "       [ 0.23890871],\n",
       "       [ 0.17877481],\n",
       "       [ 0.23599514],\n",
       "       [ 0.2252047 ],\n",
       "       [ 0.14147514],\n",
       "       [ 0.14395888],\n",
       "       [ 0.16847597],\n",
       "       [ 0.22714186],\n",
       "       [ 0.13529896],\n",
       "       [ 0.0714789 ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.15254316568314696"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2:28:00 time.\n",
    "# Since we do not have the model.predict method, we have to pass the test set data through the neural network.\n",
    "# Using the same forward propogation to get the training and test set predictions.\n",
    "\n",
    "# we take the weights and multiply them with the training set and run the sigmoid function on it. \n",
    "# same thing is done on the test set. \n",
    "# Threshold of 0.5 is applied so that values are collected as 1 or 0.\n",
    "# The sigmoid is done to get the final predictions. \n",
    "\n",
    "nn_tr_predict = sc.special.expit(np.dot(w.T,X_train_n)+b) > 0.5 # Training set prediction\n",
    "nn_ts_predict = sc.special.expit(np.dot(w.T,X_test_n)+b) > 0.5 # Test set prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy score, confusion score on the training and test set\n",
    "acc_tr = accuracy_score(y_pred = nn_tr_predict[0], y_true = y_train_n[0])\n",
    "acc_ts = accuracy_score(y_pred = nn_ts_predict[0], y_true = y_test_n[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc 0.9604395604395605 Test Acc 0.9912280701754386\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Acc {acc_tr} Test Acc {acc_ts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Test Set #\n",
      "[[72  0]\n",
      " [ 1 41]]\n"
     ]
    }
   ],
   "source": [
    "# Test set confusion matrix\n",
    "print(\"# Test Set #\")\n",
    "print(confusion_matrix(y_pred = nn_ts_predict[0], y_true = y_test_n[0]))\n",
    "\n",
    "# On test set, it has misclassified only 1 recoed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Training Set #\n",
      "[[277   8]\n",
      " [ 10 160]]\n"
     ]
    }
   ],
   "source": [
    "# Training set confusion matrix\n",
    "print(\"# Training Set #\")\n",
    "print(confusion_matrix(y_pred = nn_tr_predict[0], y_true = y_train_n[0]))\n",
    "\n",
    "# On training set, it has misclassified 18 recoeds. \n",
    "# more the misclassified records, more inaccurate is the NN model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# overfitting is addressed by regulerization\n",
    "# underfitting means performance is not complete. \n",
    "\n",
    "# If we add more layers or neurons to prevent underfitting. \n",
    "# However, in this example, NN is very simple (no hidden layer) therfore we are solely reliing on NN.\n",
    "\n",
    "# Plot how the cost keeps reducing. \n",
    "# The cost has come down to 0.2 slowly with the increasing number of epochs.\n",
    "# Using the for/back propogation, it was able to reduce the weight. \n",
    "# probably this is not the optimal weights. \n",
    "# With higher epochs, we will get better results on the training set. \n",
    "# \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (12,6))\n",
    "plt.plot(costs)\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Costs\")\n",
    "plt.title(\"Costs vs Iterations/Epochs\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# At time 2:37:50, there is a recap of the solution. \n",
    "\n",
    "# 2:50:00, final closing chapter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
